{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7c9c8a6-4f6a-443e-aedb-9e9d6bb27fc0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de54afe0-d25a-420b-ac7b-45705dfb42fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "# Data processing\n",
    "import numpy as np\n",
    "\n",
    "# Plot\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d988ff4-f6f2-4739-b8cf-d2e47d902470",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b5fd88b-6262-49ff-bc73-f25ed3f23c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "\n",
    "# Update config\n",
    "    # Fpath\n",
    "config.update({\"Path_root\": \"/Volumes/Expansion/User_Backup/b08209033/111-2_DA\"})\n",
    "config.update({\"Path_data\": os.path.join(config[\"Path_root\"], \"data\")})\n",
    "config.update({\"Path_src\": os.path.join(config[\"Path_root\"], \"src\")})\n",
    "config.update({\"Path_img\": os.path.join(config[\"Path_root\"], \"img\")})\n",
    "    # Fname\n",
    "config.update({\"Fname_true_state\": \"x_t.npz\"})\n",
    "config.update({\"Fname_init_state\": \"x_init.npz\"})\n",
    "config.update({\"Fname_ensemble_init_state\": \"ensemble_x_init.npz\"})\n",
    "\n",
    "# Output config\n",
    "os.chdir(config[\"Path_root\"])\n",
    "with open('config.json', 'w') as outfile:\n",
    "    json.dump(config, outfile, sort_keys=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbfc0f8-ff49-41cc-8f8a-1a0188d39460",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6be0e84-527e-420d-bc44-0c9532907193",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacobian(operator, x0, epsilon = 2e-8):\n",
    "    J = np.zeros((x0.shape[0], operator(x0).shape[0]), dtype = \"f8\")\n",
    "    for i in range(J.shape[0]):\n",
    "        x = np.copy(x0)\n",
    "        x[i] += epsilon\n",
    "        f = operator(x) - operator(x0)\n",
    "        for j in range(J.shape[1]):\n",
    "            J[i,j] = f[j]/epsilon\n",
    "    J = J.T\n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff370b08-c887-4840-a203-5f9cbcd6a711",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Lorenz96 Governing Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ad1407a-c041-4815-b855-80893a6f21c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_eqs(x):\n",
    "    \"\"\"\n",
    "    Lorenz96 model, governing equation\n",
    "    \n",
    "    Detect dimension to deal wtih ensemble data\n",
    "    \"\"\"\n",
    "    if (x.ndim == 2):\n",
    "        dy = (np.roll(x, shift = -1, axis = 0)-np.roll(x, shift = 2, axis = 0))*np.roll(x, shift = 1, axis = 0) -x + 8\n",
    "    elif (x.ndim == 3):\n",
    "        dy = (np.roll(x, shift = -1, axis = 1)-np.roll(x, shift = 2, axis = 1))*np.roll(x, shift = 1, axis = 1) -x + 8\n",
    "    else:\n",
    "        dy = None\n",
    "    return dy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c708f63b-3afa-4c7c-8f9b-af1012e81d00",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Nature Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc7ee912-d6c5-4e83-ab4c-20130c65b8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NatureRun():\n",
    "    \"\"\"\n",
    "    \n",
    "    Generate(Read) full true state data, and initial (ensemble) state data for \n",
    "    forecast-analysis cycle\n",
    "    Save above results, or detect above result\n",
    "    \"\"\"\n",
    "    def __init__(self, f, N, dT, Tmax, members,\n",
    "                 true_fname, true_fpath, \n",
    "                 init_fname, init_fpath, \n",
    "                 ensemble_init_fname, ensemble_init_fpath):\n",
    "        self.__true_data = None\n",
    "        self.__initial_data = None\n",
    "        self.__ensemble_initial_data = None\n",
    "        self.__f = f\n",
    "        self.__ndim = N\n",
    "        self.__dT = dT\n",
    "        self.__nT = int(Tmax/dT)+1\n",
    "        self.__Tmax = dT*int(Tmax/dT)\n",
    "        self.__time = np.linspace(0, dT*int(Tmax/dT), int(Tmax/dT)+1)\n",
    "        self.__members = members\n",
    "        self.__true_data_fname = true_fname\n",
    "        self.__true_data_fpath = true_fpath\n",
    "        self.__init_data_fname = init_fname\n",
    "        self.__init_data_fpath = init_fpath\n",
    "        self.__ensemble_init_data_fname = ensemble_init_fname\n",
    "        self.__ensemble_init_data_fpath = ensemble_init_fpath\n",
    "        return None\n",
    "    def __dynamical_operator(self, x):\n",
    "        \"\"\"\n",
    "        Doing time integration using Runge-Kutta 5 scheme\n",
    "        \"\"\"\n",
    "        k1 = self.__f(x)\n",
    "        k2 = self.__f(x + k1*self.__dT/2)\n",
    "        k3 = self.__f(x + (3*k1+k2)*self.__dT/16)\n",
    "        k4 = self.__f(x + k3*self.__dT/2)\n",
    "        k5 = self.__f(x + (-3*k2+6*k3+9*k4)*self.__dT/16)\n",
    "        k6 = self.__f(x + (k1+4*k2+6*k3-12*k4+8*k5)*self.__dT/7)\n",
    "        new_x = x + (self.__dT/90)*(7*k1 + 32*k3 + 12*k4 + 32*k5 + 7*k6)\n",
    "        return new_x\n",
    "    def __generate_initial_data(self, seed = 9527):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        np.random.seed(seed)\n",
    "        Tspinup = 100\n",
    "        scaler = 0.1\n",
    "        IC = (scaler*np.random.randn(self.__ndim)).reshape(-1, 1).astype('f8')\n",
    "        for i in range(Tspinup):\n",
    "            IC = self.__dynamical_operator(IC)\n",
    "        return IC\n",
    "    def __generate_ensemble_initial_data(self, seed = 9527):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        np.random.seed(seed)\n",
    "        deterministic_RNG = np.random.randint(int(1e6), size = self.__members)\n",
    "        ICs = []\n",
    "        for i in range(self.__members):\n",
    "            ICs.append(self.__generate_initial_data(deterministic_RNG[i]))\n",
    "        ICs = np.array(ICs, dtype = \"f8\")\n",
    "        return ICs\n",
    "    def __generate_true_data(self, seed = 9527):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        x_t = [self.__generate_initial_data(seed)]\n",
    "        for i in range(self.__nT-1):\n",
    "            x_t.append(self.__dynamical_operator(x_t[i]))\n",
    "        x_t = np.array(x_t, dtype = \"f8\")\n",
    "        return x_t\n",
    "    def get_True_data(self):\n",
    "        return self.__true_data\n",
    "    def get_Initial_data(self):\n",
    "        return self.__initial_data\n",
    "    def get_Ensemble_initial_data(self):\n",
    "        return self.__ensemble_initial_data\n",
    "    def get_Governing_equation(self):\n",
    "        return self.__f\n",
    "    def get_Dimension(self):\n",
    "        return self.__ndim\n",
    "    def get_Time(self):\n",
    "        return self.__time\n",
    "    def get_unit_timestep(self):\n",
    "        return self.__dT\n",
    "    def get_total_timestep(self):\n",
    "        return self.__nT\n",
    "    def initialize(self, seed1 = 1234, seed2 = 5678, seed3 = 9012):\n",
    "        \"\"\"\n",
    "        Detect if file existed, and if format shape is qualified, \n",
    "        and do following things\n",
    "        \n",
    "        Generate data and save \n",
    "        Read data\n",
    "        \"\"\"\n",
    "        print(\"Simluation time:\")\n",
    "        print(self.__time)\n",
    "        print()\n",
    "        \n",
    "        # True state\n",
    "        print(\"True state:\")\n",
    "        fpath = os.path.join(self.__true_data_fpath, self.__true_data_fname)\n",
    "        if not os.path.exists(fpath):\n",
    "            x_t = self.__generate_true_data(seed1)\n",
    "            print(f\"Generate new true state.\")\n",
    "            self.__true_data = x_t\n",
    "            os.chdir(self.__true_data_fpath)\n",
    "            np.savez(self.__true_data_fname, \n",
    "                     data = x_t, \n",
    "                     time = self.__time, \n",
    "                     space = np.array([self.__ndim, 1]))\n",
    "            print(f\"Store new true state.\")\n",
    "        else:\n",
    "            ticks = os.path.getmtime(fpath)\n",
    "            realtime = datetime.datetime.fromtimestamp(ticks)\n",
    "            os.chdir(self.__true_data_fpath)\n",
    "            infile = np.load(self.__true_data_fname)\n",
    "            print(f\"True state had been stored.\\nLast modified: {realtime}\")\n",
    "            if (np.array_equal(infile[\"time\"], self.__time)):\n",
    "                x_t = infile[\"data\"]\n",
    "                self.__true_data = x_t\n",
    "            else:\n",
    "                print(\"Mismatch data shape, generate new true state.\")\n",
    "                x_t = self.__generate_true_data(seed1)\n",
    "                self.__true_data = x_t\n",
    "                os.chdir(self.__true_data_fpath)\n",
    "                np.savez(self.__true_data_fname, \n",
    "                         data = x_t, \n",
    "                         time = self.__time, \n",
    "                         space = np.array([self.__ndim, 1]))\n",
    "                print(f\"Store new true state.\")\n",
    "        print(\"Shape: \",x_t.shape)\n",
    "        print();print();\n",
    "        \n",
    "        # Init state\n",
    "        print(\"Initial state:\")\n",
    "        fpath = os.path.join(self.__init_data_fpath, self.__init_data_fname)\n",
    "        if not os.path.exists(fpath):\n",
    "            x_init = self.__generate_initial_data(seed2)\n",
    "            print(f\"Generate new initial state.\")\n",
    "            self.__initial_data = x_init\n",
    "            os.chdir(self.__init_data_fpath)\n",
    "            np.savez(self.__init_data_fname, \n",
    "                     data = x_init, \n",
    "                     time = self.__time, \n",
    "                     space = np.array([self.__ndim, 1]))\n",
    "            print(f\"Store new initial state.\")\n",
    "        else:\n",
    "            ticks = os.path.getmtime(fpath)\n",
    "            realtime = datetime.datetime.fromtimestamp(ticks)\n",
    "            os.chdir(self.__init_data_fpath)\n",
    "            infile = np.load(self.__init_data_fname)\n",
    "            print(f\"Initial state had been stored.\\nLast modified: {realtime}\")\n",
    "            if (np.array_equal(infile[\"time\"], self.__time)):\n",
    "                x_init = infile[\"data\"]\n",
    "                self.__initial_data = x_init\n",
    "            else:\n",
    "                print(\"Mismatch data shape, generate new initial state.\")\n",
    "                x_init = self.__generate_initial_data(seed2)\n",
    "                self.__initial_data = x_init\n",
    "                os.chdir(self.__init_data_fpath)\n",
    "                np.savez(self.__init_data_fname, \n",
    "                         data = x_init, \n",
    "                         time = self.__time, \n",
    "                         space = np.array([self.__ndim, 1]))\n",
    "                print(f\"Store new initial state.\")\n",
    "        print(\"Shape: \",x_init.shape)\n",
    "        print();print();\n",
    "        \n",
    "        # Ensemble init state\n",
    "        print(\"Ensemble initital state:\")\n",
    "        fpath = os.path.join(self.__ensemble_init_data_fpath, self.__ensemble_init_data_fname)\n",
    "        if not os.path.exists(fpath):\n",
    "            ensemble_x_init = self.__generate_ensemble_initial_data(seed3)\n",
    "            print(f\"Generate new ensemble initial state.\")\n",
    "            self.__ensemble_initial_data = ensemble_x_init\n",
    "            os.chdir(self.__ensemble_init_data_fpath)\n",
    "            np.savez(self.__ensemble_init_data_fname, \n",
    "                     data = ensemble_x_init, \n",
    "                     time = self.__time, \n",
    "                     space = np.array([self.__members, self.__ndim, 1]))\n",
    "            print(f\"Store new ensemble initial state.\")\n",
    "        else:\n",
    "            ticks = os.path.getmtime(fpath)\n",
    "            realtime = datetime.datetime.fromtimestamp(ticks)\n",
    "            os.chdir(self.__ensemble_init_data_fpath)\n",
    "            infile = np.load(self.__ensemble_init_data_fname)\n",
    "            print(f\"Ensemble initial state had been stored.\\nLast modified: {realtime}\")\n",
    "            if (np.array_equal(infile[\"time\"], self.__time)) and (infile[\"space\"][0]==self.__members):\n",
    "                ensemble_x_init = infile[\"data\"]\n",
    "                self.__ensemble_initial_data = ensemble_x_init\n",
    "            else:\n",
    "                print(\"Mismatch data shape, generate new ensemble initial state.\")\n",
    "                ensemble_x_init = self.__generate_ensemble_initial_data(seed3)\n",
    "                self.__ensemble_initial_data = ensemble_x_init\n",
    "                os.chdir(self.__ensemble_init_data_fpath)\n",
    "                np.savez(self.__ensemble_init_data_fname, \n",
    "                         data = ensemble_x_init, \n",
    "                         time = self.__time, \n",
    "                         space = np.array([self.__members,self.__ndim, 1]))\n",
    "                print(f\"Store new ensemble initial state.\")\n",
    "        print(\"Shape: \",ensemble_x_init.shape)\n",
    "        print();print();\n",
    "        \n",
    "        return (x_t, x_init, ensemble_x_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c235deee-9ba3-452a-a1df-f5bec8bac33c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Observation state & operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc63526a-b133-4cd4-aa1c-64d64cc3ad7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Observation_data():\n",
    "    \"\"\"\n",
    "    Generate observation data according to true state data, which is\n",
    "    observation = true_state + error\n",
    "    However, some modifications may be applied\n",
    "    1. Time scheme, observation time may vary to true state time\n",
    "    2. Space scheme, observation location may different to true state location\n",
    "    3. Error scheme, observation error may vary by its generator\n",
    "    \n",
    "    Here, I use a tricky method, that I assumed fully-observation and generate\n",
    "    fully_observation data within class, but the actual get method would be limited by \n",
    "    previous scheme\n",
    "    \n",
    "    Also, the precision accuracy in python make search algorithm invalid, for \n",
    "    the actual time sometimes lost accuracy, a round-off is applied when dealing\n",
    "    with time data\n",
    "    \"\"\"\n",
    "    def __init__(self, ref_data, ref_time):\n",
    "        self.__reference_data = ref_data\n",
    "        self.__reference_time = np.round(ref_time, 5)\n",
    "        self.__observation_data = None\n",
    "        self.__observation_error = None\n",
    "        self.__observation_time = None\n",
    "        self.__observation_time_filter = None\n",
    "        self.__observation_space = None\n",
    "        self.__observation_space_filter = None\n",
    "        self.__observation_Rstd = None\n",
    "    def __observation_time_scheme(self, opt = 1):\n",
    "        \"\"\"\n",
    "        Define sub function, employ \"time structure\" of observation data\n",
    "        Scheme:\n",
    "        Full coverage (opt==1): each background correspond to one observation\n",
    "        Sparse coverage (opt==2): 50% background correspond to one observation, and observation are equally spaced\n",
    "        Initial coverage (opt==3): Only first 30% background correspond to one observation\n",
    "        \"\"\"\n",
    "        def full_time():\n",
    "            \"\"\"\n",
    "            Time structure of observation data\n",
    "            All-time observation\n",
    "            \"\"\"\n",
    "            _time = np.round(self.__reference_time, 5)\n",
    "            _filter = np.full(self.__reference_time.shape, True)\n",
    "            return _time, _filter\n",
    "        def sparse_time():\n",
    "            \"\"\"\n",
    "            Time structure of observation data\n",
    "            Adjacent-spaced observation\n",
    "            \"\"\"\n",
    "            _time = np.round(self.__reference_time, 5)[::2]\n",
    "            _filter = np.full(self.__reference_time.shape, False)\n",
    "            _filter[::2] = True\n",
    "            return _time, _filter\n",
    "        def initial_time():\n",
    "            \"\"\"\n",
    "            Time structure of observation data\n",
    "            Only first 30% observation of all simulations\n",
    "            \"\"\"\n",
    "            _time = np.round(self.__reference_time, 5)[:int(len(self.__reference_time)*.3)]\n",
    "            _filter = np.full(self.__reference_time.shape, False)\n",
    "            _filter[:int(len(self.__reference_time)*.3)] = True\n",
    "            return _time, _filter\n",
    "        \n",
    "        # Choose scheme\n",
    "        if (opt == 1):\n",
    "            _time, _filter = full_time()\n",
    "        elif (opt == 2):\n",
    "            _time, _filter = sparse_time()\n",
    "        elif (opt == 3):\n",
    "            _time, _filter = initial_time()\n",
    "        else:\n",
    "            _time, _filter = None, None\n",
    "        self.__observation_time = _time\n",
    "        self.__observation_time_filter = _filter\n",
    "        return None\n",
    "    def __observation_space_scheme(self, opt = 1):\n",
    "        \"\"\"\n",
    "        Define sub function, employ \"space structure\" of observation data\n",
    "        Scheme:\n",
    "        Full coverage (opt==1): each location correspond to one observation at valid time\n",
    "        Sparse coverage (opt==2): 50% location correspond to one observation, and locations are cyclic at valid time\n",
    "        Initial coverage (opt==3): Only 50% background correspond to one observation, purely random at valid time\n",
    "        \"\"\"\n",
    "        def full_space():\n",
    "            \"\"\"\n",
    "            All locations with observations at valid time\n",
    "            \"\"\"\n",
    "            _space = np.repeat(np.arange(40).reshape(1,-1,1), len(self.__reference_time), axis = 0)\n",
    "            _filter = np.full(self.__reference_data.shape, True)\n",
    "            return _space, _filter\n",
    "        def regular_sparse_space(sparse = 20):\n",
    "            \"\"\"\n",
    "            Half-sparse locations with observations at valid time\n",
    "            \"\"\"\n",
    "            _space = np.repeat(np.arange(40).reshape(1,-1,1), len(self.__reference_time), axis = 0)\n",
    "            _filter = np.full(self.__reference_data.shape, False)\n",
    "            ndim = self.__reference_data.shape[1]\n",
    "            for i in range(self.__reference_data.shape[0]):\n",
    "                observation_range = ((i*sparse)%ndim ,((i+1)*sparse-1)%ndim+1)\n",
    "                if (observation_range[0] > observation_range[1]):\n",
    "                    _space[i,:observation_range[1],:] = -1\n",
    "                    _space[i,observation_range[0]:,:] = -1\n",
    "                    _filter[i,:observation_range[1],:] = True\n",
    "                    _filter[i,observation_range[0]:,:] = True\n",
    "                else:\n",
    "                    _space[i,observation_range[0]:observation_range[1],:] = -1\n",
    "                    _filter[i,observation_range[0]:observation_range[1],:] = True\n",
    "            return _space, _filter\n",
    "        def random_sparse_space(percent = 0.5, seed = len(self.__reference_time)):\n",
    "            \"\"\"\n",
    "            Random-sparse locations with observations at valid time\n",
    "            \"\"\"\n",
    "            np.random.seed(seed)\n",
    "            deterministic_RNG = np.random.randint(int(1e6), size = len(self.__observation_time))\n",
    "            \n",
    "            _filter = np.full(self.__reference_data.shape, True)\n",
    "            _space = np.repeat(np.arange(40).reshape(1,-1,1), len(self.__reference_time), axis = 0)\n",
    "            for i in range(len(self.__observation_time)):\n",
    "                np.random.seed(deterministic_RNG[i])\n",
    "                _filter[i] = np.random.choice(a = [False, True], size = (self.__reference_data.shape[1]), p = [1-percent, percent]).reshape(-1,1)\n",
    "                _space[np.where(np.logical_not(_filter[i]))[0]] = -1\n",
    "            return _space, _filter\n",
    "        # Choose scheme\n",
    "        if (opt == 1):\n",
    "            _space, _filter = full_space()\n",
    "        elif (opt == 2):\n",
    "            _space, _filter = regular_sparse_space()\n",
    "        elif (opt == 3):\n",
    "            _space, _filter = random_sparse_space()\n",
    "        else:\n",
    "            _space, _filter = None, None\n",
    "        self.__observation_space = _space\n",
    "        self.__observation_space_filter = _filter\n",
    "        return None\n",
    "    def __reset_observation(self):\n",
    "        \"\"\"\n",
    "        Reset observation to reference state, which is\n",
    "        observation = ObsOp(reference) = reference, at valid time\n",
    "        \"\"\"\n",
    "        self.__observation_data = self.__reference_data\n",
    "        return self.__reference_data\n",
    "    def __random_error_scheme(self, std, opt = 1, seed = 9527):\n",
    "        \"\"\"\n",
    "        Define sub function employ observation error following specific characteristic\n",
    "        Scheme\n",
    "        Pure RNG (opt==1): using scaled white noise\n",
    "        \"\"\"\n",
    "        def PRNG(std, seed = 9527):\n",
    "            \"\"\"\n",
    "            Generate error by white noise\n",
    "            \"\"\"\n",
    "            # Deterministic outer seed\n",
    "            np.random.seed(seed)\n",
    "            error = np.random.normal(loc = 0, scale = std, size = self.__observation_data.shape)\n",
    "            R = np.eye(self.__reference_data.shape[1])*std**2\n",
    "            return (error, R)\n",
    "        # Reset std\n",
    "        self.__observation_Rstd = std\n",
    "        # Choose scheme\n",
    "        if (opt == 1):\n",
    "            error, R = PRNG(std = std, seed = seed)\n",
    "        else:\n",
    "            error = None\n",
    "            R = None\n",
    "        self.__observation_error = error\n",
    "        self.__observation_R = R\n",
    "        return error\n",
    "    def __fill_observation_error(self, error):\n",
    "        \"\"\"\n",
    "        Adding observation error to observation data\n",
    "        \"\"\"\n",
    "        self.__observation_data = self.__observation_data + error\n",
    "        return self.__observation_data\n",
    "    def generate(self, time_scheme = 1, space_scheme = 1, error_scheme = 1, std = 1):\n",
    "        \"\"\"\n",
    "        Find valid time with observation\n",
    "        Generate observation operator\n",
    "        Reset observation\n",
    "        Generate observation error\n",
    "        Generate observation\n",
    "        *** Compile sequence matters, dont move it!\n",
    "        \"\"\"\n",
    "        self.__observation_time_scheme(opt = time_scheme)\n",
    "        self.__observation_space_scheme(opt = space_scheme)\n",
    "        self.__reset_observation()\n",
    "        error = self.__random_error_scheme(std, opt = error_scheme)\n",
    "        self.__fill_observation_error(error)\n",
    "        return None\n",
    "    def __check_valid_time(self, time = None):\n",
    "        \"\"\"\n",
    "        Return true if given time correspond to observations, else false\n",
    "        \"\"\"\n",
    "        return np.any(self.__observation_time == time)\n",
    "    def get_Operator(self, time = None, safe = False):\n",
    "        \"\"\"\n",
    "        Return observation operator at given time if possible\n",
    "        \"\"\"\n",
    "        def abstract_Operator(H, x):\n",
    "            return H@x\n",
    "        def instance_Operator(_filter):\n",
    "            return lambda x: abstract_Operator(np.eye(self.__reference_data.shape[1])[_filter.flatten()], x)\n",
    "        \n",
    "        # Single-time\n",
    "        if (isinstance(time, (int, float))):\n",
    "            time = round(time, 5)\n",
    "            if (self.__check_valid_time(time) or safe):\n",
    "                idx = int(np.argwhere(self.__reference_time == time))\n",
    "                space_filter = self.__observation_space_filter[idx]\n",
    "                return instance_Operator(space_filter)\n",
    "            else:\n",
    "                return None\n",
    "        # Several-time\n",
    "        elif (isinstance(time, tuple)):\n",
    "            time = (round(time[0], 5), round(time[1], 5))\n",
    "            # Find observation between\n",
    "            idx = np.logical_and(time[0] <= self.__observation_time, self.__observation_time <= time[1])\n",
    "            # Check emptyness\n",
    "            if (not idx.any()):\n",
    "                return None\n",
    "            else:\n",
    "                idx = self.__observation_time[idx]\n",
    "                return [self.get_Operator(i) for i in idx]\n",
    "        else:\n",
    "            return None\n",
    "    def get_Data(self, time = None):\n",
    "        \"\"\"\n",
    "        Return observation data at given time if possible\n",
    "        \"\"\"\n",
    "        # Single-time\n",
    "        if (isinstance(time, (int, float))):\n",
    "            time = round(time, 5)\n",
    "            if self.__check_valid_time(time):\n",
    "                # Find closest observation\n",
    "                idx = int(np.argwhere(self.__reference_time == time))\n",
    "                return self.get_Operator(time, safe = True)(self.__observation_data[idx])\n",
    "            else:\n",
    "                return None\n",
    "        # Several-time\n",
    "        elif (isinstance(time, tuple)):\n",
    "            time = (round(time[0], 5), round(time[1], 5))\n",
    "            # Find observation between\n",
    "            idx = np.logical_and(time[0] <= self.__observation_time, self.__observation_time <= time[1])\n",
    "            # Check emptyness\n",
    "            if (not idx.any()):\n",
    "                return None\n",
    "            else:\n",
    "                idx = self.__observation_time[idx]\n",
    "                \n",
    "                return [self.get_Data(i) for i in idx]\n",
    "        else:\n",
    "            return None\n",
    "    def get_Covariance(self, time):\n",
    "        \"\"\"\n",
    "        Return observation covariance at given time if possible\n",
    "        \"\"\"\n",
    "        # Single-time\n",
    "        if (isinstance(time, (int, float))):\n",
    "            time = round(time, 5)\n",
    "            if self.__check_valid_time(time):\n",
    "                idx = int(np.argwhere(self.__reference_time == time))\n",
    "                return np.eye(np.sum(self.__observation_space_filter[idx]))*self.__observation_Rstd**2\n",
    "            else:\n",
    "                return None\n",
    "        # Several-time\n",
    "        elif (isinstance(time, tuple)):\n",
    "            time = (round(time[0], 5), round(time[1], 5))\n",
    "            # Find observation between\n",
    "            idx = np.logical_and(time[0] <= self.__observation_time, self.__observation_time <= time[1])\n",
    "            # Check emptyness\n",
    "            if (not idx.any()):\n",
    "                return None\n",
    "            else:\n",
    "                idx = self.__observation_time[idx]\n",
    "                \n",
    "                return [self.get_Covariance(i) for i in idx]\n",
    "        else:\n",
    "            return None\n",
    "    def get_Trajectory(self, loc):\n",
    "        \"\"\"\n",
    "        Non-filtered observation trajectory\n",
    "        \"\"\"\n",
    "        return (self.__observation_data[:,loc,:], self.__observation_space_filter[:,loc,:])\n",
    "    def get_Error(self):\n",
    "        return self.__observation_error\n",
    "    def get_Time(self):\n",
    "        return self.__observation_time\n",
    "    def get_Rstd(self):\n",
    "        return self.__observation_Rstd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5219828-9ae7-4c2c-8117-44fdd346c647",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Assimilation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8268d2e9-0119-4538-8adc-5466216c2c1b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## No DA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23ef2ae9-d9df-455f-89a5-c2416ded50ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simulator_NoDA():\n",
    "    def __init__(self,\n",
    "                 nature_run,\n",
    "                 observation):\n",
    "        self.__observation = observation\n",
    "        self.__initial_x_a = nature_run.get_Initial_data()\n",
    "        self.__initial_x_b = np.full(self.__initial_x_a.shape, np.nan, dtype = \"f8\")\n",
    "        self.__B = np.eye(nature_run.get_Dimension())*observation.get_Rstd()**2\n",
    "        self.__func = nature_run.get_Governing_equation()\n",
    "        self.__dT = nature_run.get_unit_timestep()\n",
    "        self.__nT = nature_run.get_total_timestep()\n",
    "        return None\n",
    "    def __model(self, x):\n",
    "        \"\"\"\n",
    "        Doing time integration using Runge-Kutta 4 scheme\n",
    "        \"\"\"\n",
    "        k1 = self.__func(x)\n",
    "        k2 = self.__func(x + k1*self.__dT/2)\n",
    "        k3 = self.__func(x + (3*k1+k2)*self.__dT/16)\n",
    "        k4 = self.__func(x + k3*self.__dT/2)\n",
    "        k5 = self.__func(x + (-3*k2+6*k3+9*k4)*self.__dT/16)\n",
    "        k6 = self.__func(x + (k1+4*k2+6*k3-12*k4+8*k5)*self.__dT/7)\n",
    "        new_x = x + (self.__dT/90)*(7*k1 + 32*k3 + 12*k4 + 32*k5 + 7*k6)\n",
    "        return new_x\n",
    "    def Cycle(self):\n",
    "        observation = self.__observation\n",
    "        x_b_all = self.__initial_x_b[np.newaxis]\n",
    "        x_a_all = self.__initial_x_a[np.newaxis]\n",
    "        ct = 0\n",
    "        while ct < (self.__nT-1):\n",
    "            # Forecast\n",
    "            x_b = self.__model(x_a_all[ct])[np.newaxis]\n",
    "            x_b_all = np.vstack([x_b_all, x_b])\n",
    "            # Analysis\n",
    "            x_b = x_b_all[ct+1]\n",
    "            y_o = observation.get_Data((ct+1)*self.__dT)\n",
    "            R = observation.get_Covariance((ct+1)*self.__dT)\n",
    "            H = observation.get_Operator((ct+1)*self.__dT)\n",
    "            x_a = x_b[np.newaxis]\n",
    "            x_a_all = np.vstack([x_a_all, x_a])\n",
    "            # next\n",
    "            ct += 1\n",
    "        return x_a_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e6d35f-c62a-453c-b1c1-6183c8e8b88e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## OI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af7e1654-43d8-4e7d-86ae-a53c25375139",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simulator_OI():\n",
    "    \"\"\"\n",
    "    Implement forecast-analysis cycle using OI scheme\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 nature_run,\n",
    "                 observation):\n",
    "        self.__observation = observation\n",
    "        self.__initial_x_a = nature_run.get_Initial_data()\n",
    "        self.__initial_x_b = np.full(self.__initial_x_a.shape, np.nan, dtype = \"f8\")\n",
    "        self.__B = np.eye(nature_run.get_Dimension())*observation.get_Rstd()**2\n",
    "        self.__Bi = np.linalg.inv(self.__B)\n",
    "        self.__func = nature_run.get_Governing_equation()\n",
    "        self.__dT = nature_run.get_unit_timestep()\n",
    "        self.__nT = nature_run.get_total_timestep()\n",
    "        return None\n",
    "    def __model(self, x):\n",
    "        \"\"\"\n",
    "        Doing time integration using Runge-Kutta 5 scheme\n",
    "        \"\"\"\n",
    "        k1 = self.__func(x)\n",
    "        k2 = self.__func(x + k1*self.__dT/2)\n",
    "        k3 = self.__func(x + (3*k1+k2)*self.__dT/16)\n",
    "        k4 = self.__func(x + k3*self.__dT/2)\n",
    "        k5 = self.__func(x + (-3*k2+6*k3+9*k4)*self.__dT/16)\n",
    "        k6 = self.__func(x + (k1+4*k2+6*k3-12*k4+8*k5)*self.__dT/7)\n",
    "        new_x = x + (self.__dT/90)*(7*k1 + 32*k3 + 12*k4 + 32*k5 + 7*k6)\n",
    "        return new_x\n",
    "    def __OI(self, x_b, y_o, H, R):\n",
    "        \"\"\"\n",
    "        Data assimilation using optimal interpolation\n",
    "        \n",
    "        x_a = x_b + K@[y_o - H(x_b)]\n",
    "        K = A@H.T@R-1\n",
    "        A-1 = B-1 + H.T@R-1@H\n",
    "        \"\"\"\n",
    "        d = y_o - H(x_b)\n",
    "        Hl = jacobian(H, x_b)\n",
    "        Ri = np.linalg.inv(R)\n",
    "        A = np.linalg.inv(self.__Bi + Hl.T@Ri@Hl)\n",
    "        K = A@Hl.T@Ri\n",
    "        x_a = x_b + K@d\n",
    "        return x_a\n",
    "    def Cycle(self):\n",
    "        \"\"\"\n",
    "        Forecast-Analysis Cycle\n",
    "        \"\"\"\n",
    "        observation = self.__observation\n",
    "        x_b_all = self.__initial_x_b[np.newaxis]\n",
    "        x_a_all = self.__initial_x_a[np.newaxis]\n",
    "        ct = 0\n",
    "        while ct < (self.__nT-1):\n",
    "            # Forecast\n",
    "            x_b = self.__model(x_a_all[ct])[np.newaxis]     \n",
    "            x_b_all = np.vstack([x_b_all, x_b])\n",
    "            # Analysis\n",
    "            x_b = x_b_all[ct+1]\n",
    "            y_o = observation.get_Data((ct+1)*self.__dT)\n",
    "            H = observation.get_Operator((ct+1)*self.__dT)\n",
    "            R = observation.get_Covariance((ct+1)*self.__dT)\n",
    "            if y_o is not None:\n",
    "                x_a = self.__OI(x_b, y_o, H, R)[np.newaxis]\n",
    "            else:\n",
    "                x_a = x_b[np.newaxis]\n",
    "            x_a_all = np.vstack([x_a_all, x_a])\n",
    "            # next\n",
    "            ct += 1\n",
    "        return x_a_all\n",
    "    def NMC(self, x_a_all, inflation = 0.25):\n",
    "        \"\"\"\n",
    "        Derive statistical BEC using NMC\n",
    "        In this case, following Prof's advice, using\n",
    "        Long forecast = 8 timestep\n",
    "        Short forecast = 4 timestep\n",
    "        By deduct different forecast at same valid time, expect the BEC structure\n",
    "        can be revealed.\n",
    "        \"\"\"\n",
    "        # Algorithm parameter\n",
    "        long_forecast_length = 8\n",
    "        short_forecast_length = 4\n",
    "        forecast_length = long_forecast_length + 1\n",
    "        N_samples = np.shape(x_a_all)[0]\n",
    "        # Init\n",
    "        samples = np.zeros((N_samples, forecast_length, np.shape(x_a_all)[-2], 1))\n",
    "        \n",
    "        # Forecast in each sampled analysis time\n",
    "        for idx_samples in range(N_samples):\n",
    "            current_x_b = x_a_all[idx_samples]\n",
    "            samples[idx_samples,0] = current_x_b\n",
    "            for idx_forecast in range(forecast_length-1):\n",
    "                # Forecast\n",
    "                new_x_b = self.__model(current_x_b)\n",
    "                current_x_b = new_x_b\n",
    "                \n",
    "                samples[idx_samples,idx_forecast+1] = current_x_b\n",
    "                \n",
    "        # Deduct different forecast length at same valid time\n",
    "        samples_diff = samples[:-(long_forecast_length-short_forecast_length),long_forecast_length] - samples[(long_forecast_length-short_forecast_length):,short_forecast_length]\n",
    "        # Calculate statistical BEC\n",
    "        NMC_B = np.zeros((np.shape(x_a_all)[-2], np.shape(x_a_all)[-2]))\n",
    "        for i in range(len(samples_diff)):\n",
    "            d = samples_diff[i]\n",
    "            NMC_B += (d@d.T/(np.shape(samples_diff)[0]-1))\n",
    "        # Inflate\n",
    "        NMC_B *= inflation\n",
    "        return NMC_B\n",
    "    def set_B(self, B):\n",
    "        self.__B = B\n",
    "        self.__Bi = np.linalg.inv(self.__B)\n",
    "        return None\n",
    "    def get_B(self):\n",
    "        return self.__B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bf5a7f-8656-41fa-9f9a-42d944490aab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 3DVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "199ede39-7882-4180-9a0f-63aae6e46b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simulator_3DVar():\n",
    "    \"\"\"\n",
    "    Implement forecast-analysis cycle using 3DVar scheme\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 nature_run,\n",
    "                 observation):\n",
    "        self.__observation = observation\n",
    "        self.__initial_x_a = nature_run.get_Initial_data()\n",
    "        self.__initial_x_b = np.full(self.__initial_x_a.shape, np.nan, dtype = \"f8\")\n",
    "        self.__B = np.eye(nature_run.get_Dimension())*observation.get_Rstd()**2\n",
    "        self.__Bi = np.linalg.inv(self.__B)\n",
    "        self.__func = nature_run.get_Governing_equation()\n",
    "        self.__dT = nature_run.get_unit_timestep()\n",
    "        self.__nT = nature_run.get_total_timestep()\n",
    "        return None\n",
    "    def __model(self, x):\n",
    "        \"\"\"\n",
    "        Doing time integration using Runge-Kutta 5 scheme\n",
    "        \"\"\"\n",
    "        k1 = self.__func(x)\n",
    "        k2 = self.__func(x + k1*self.__dT/2)\n",
    "        k3 = self.__func(x + (3*k1+k2)*self.__dT/16)\n",
    "        k4 = self.__func(x + k3*self.__dT/2)\n",
    "        k5 = self.__func(x + (-3*k2+6*k3+9*k4)*self.__dT/16)\n",
    "        k6 = self.__func(x + (k1+4*k2+6*k3-12*k4+8*k5)*self.__dT/7)\n",
    "        new_x = x + (self.__dT/90)*(7*k1 + 32*k3 + 12*k4 + 32*k5 + 7*k6)\n",
    "        return new_x\n",
    "    def __increment_3DVar(self, x_b, y_o, H, Ri):\n",
    "        \"\"\"\n",
    "        Data assimilation using 3DVar, in this case, using incremental form\n",
    "        \"\"\"\n",
    "        def f(dx, x_a, x_b, d, Hl, Ri):\n",
    "            \"\"\"\n",
    "            Cost function of 3DVar in incremental form\n",
    "            J = 1/2*(dx.T@B-1@dx + (H@dx - d)@R-1@(H@dx - d))\n",
    "            \"\"\"\n",
    "            # Rename\n",
    "            increment = dx\n",
    "            past_state = x_a\n",
    "            current_state = past_state + increment\n",
    "            background_state = x_b\n",
    "            innovation = d\n",
    "            LinObsOp = Hl\n",
    "            \n",
    "            J_b = (1/2)*(current_state - background_state).T@self.__Bi@(current_state - background_state)\n",
    "            J_o = (1/2)*(LinObsOp@increment - innovation).T@Ri@(LinObsOp@increment - innovation)\n",
    "            J = J_b + J_o\n",
    "            return J\n",
    "        def fprime(dx, x_a, x_b, d, Hl, Ri):\n",
    "            \"\"\"\n",
    "            Jacobian of cost function of 3DVar in incremental form\n",
    "            dJ = B-1@dx + H.T@R-1@(H@dx - d)\n",
    "            \"\"\"\n",
    "            # Rename\n",
    "            increment = dx\n",
    "            past_state = x_a\n",
    "            current_state = past_state + increment\n",
    "            background_state = x_b\n",
    "            innovation = d\n",
    "            LinObsOp = Hl\n",
    "            \n",
    "            J_b = self.__Bi@(current_state - background_state)\n",
    "            J_o = (LinObsOp.T)@Ri@(LinObsOp@increment - innovation)\n",
    "            J = J_b + J_o\n",
    "            return J\n",
    "        def line_search(f, grad, dx, args = ()):\n",
    "            \"\"\"\n",
    "            Modified from Golden Section Line Search\n",
    "            Given object function, its gradient and reference state\n",
    "            Find step (p_k) that minimize f, which is\n",
    "            f(dx + p_k * grad) < f(dx)\n",
    "            ***May unstable due to CFL condition\n",
    "            \"\"\"\n",
    "            # Algorithm parameter\n",
    "            upper_bound = 1\n",
    "            lower_bound = -1\n",
    "            alpha = (3 - np.sqrt(5)) / 2\n",
    "            # Initialize\n",
    "            a0 = lower_bound\n",
    "            b0 = upper_bound\n",
    "            a1 = a0 + alpha*(b0-a0)\n",
    "            b1 = b0 - alpha*(b0-a0)\n",
    "            reference = f(dx, *args)\n",
    "            \n",
    "            # Find best step\n",
    "            while True:\n",
    "                result_a1 = f(dx+a1*grad, *args)\n",
    "                result_b1 = f(dx+b1*grad, *args)\n",
    "                if (result_a1 < reference):\n",
    "                    best_p = a1\n",
    "                    break\n",
    "                if (result_b1 < reference):\n",
    "                    best_p = b1\n",
    "                    break\n",
    "                if (result_a1 < result_b1):\n",
    "                    b0 = b1\n",
    "                    b1 = a1\n",
    "                    a1 = a0 + alpha*(b0-a0)\n",
    "                else:\n",
    "                    a0 = a1\n",
    "                    a1 = b1\n",
    "                    b1 = b0 - alpha*(b0-a0)\n",
    "            return best_p\n",
    "        def PR_beta(g0, g1):\n",
    "            \"\"\"\n",
    "            Polak-Ribiere method for conjugate gradient method \n",
    "            \"\"\"\n",
    "            return (g1.T@(g1-g0))/(g0.T@g0)\n",
    "        def minimize(x_b, y_o, H, Ri):\n",
    "            \"\"\"\n",
    "            Minimize cost funciton using CG method\n",
    "            \"\"\"\n",
    "            # Algorithm parameter\n",
    "            maxiter_inner = int(1e6)\n",
    "            maxiter_outer = int(1e6)\n",
    "            # First guess, x = x_b\n",
    "            x_a = np.copy(x_b)\n",
    "            \n",
    "            for out_loop in range(maxiter_outer):\n",
    "                # Initial minimization parameter\n",
    "                jac_old = np.full(np.shape(x_b), 0, dtype = \"f8\")\n",
    "                jac_new = np.full(np.shape(x_b), 0, dtype = \"f8\")\n",
    "                beta = None\n",
    "                grad = 0\n",
    "                # Initial increment\n",
    "                dx = np.full(np.shape(x_b), 0, dtype = \"f8\")\n",
    "                # Find current variable\n",
    "                d = y_o - H(x_a)\n",
    "                Hl = jacobian(H, x_a)\n",
    "                \n",
    "                # Control parameter\n",
    "                args = (x_a, x_b, d, Hl, Ri)\n",
    "                for in_loop in range(maxiter_inner):\n",
    "                    # Find gradient\n",
    "                    jac = fprime(dx, *args)\n",
    "                    jac_new = jac\n",
    "                    beta = PR_beta(jac_old, jac_new) if in_loop != 0 else 1\n",
    "                    grad = -(jac_new) + beta*grad\n",
    "                    jac_old = jac_new\n",
    "                    # Find directions and step\n",
    "                    p_k = line_search(f, grad, dx, args = args)\n",
    "                    delta = p_k*grad\n",
    "                    # Update dx\n",
    "                    dx += delta\n",
    "                    if (np.linalg.norm(delta) < 1e-4):\n",
    "                        break\n",
    "                # Update x\n",
    "                x_a += dx\n",
    "                if (np.linalg.norm(dx) < 1e-3):\n",
    "                    break\n",
    "            return x_a\n",
    "        return minimize(x_b, y_o, H, Ri)  \n",
    "        \n",
    "    def Cycle(self):\n",
    "        \"\"\"\n",
    "        Forecast-Analysis Cycle\n",
    "        \"\"\"\n",
    "        observation = self.__observation\n",
    "        x_b_all = self.__initial_x_b[np.newaxis]\n",
    "        x_a_all = self.__initial_x_a[np.newaxis]\n",
    "        ct = 0\n",
    "        while ct < (self.__nT-1):\n",
    "            # Forecast\n",
    "            x_b = self.__model(x_a_all[ct])[np.newaxis]\n",
    "            x_b_all = np.vstack([x_b_all, x_b])\n",
    "            # Analysis\n",
    "            x_b = x_b_all[ct+1]\n",
    "            y_o = observation.get_Data((ct+1)*self.__dT)\n",
    "            H = observation.get_Operator((ct+1)*self.__dT)\n",
    "            R = observation.get_Covariance((ct+1)*self.__dT)\n",
    "            if y_o is not None:\n",
    "                Ri = np.linalg.inv(R)\n",
    "                x_a = self.__increment_3DVar(x_b, y_o, H, Ri)[np.newaxis]\n",
    "            else:\n",
    "                x_a = x_b[np.newaxis]\n",
    "            \n",
    "            x_a_all = np.vstack([x_a_all, x_a])\n",
    "            # next\n",
    "            ct += 1\n",
    "        return x_a_all\n",
    "    def NMC(self, x_a_all, inflation = 0.25):\n",
    "        \"\"\"\n",
    "        Derive statistical BEC using NMC\n",
    "        In this case, following Prof's advice, using\n",
    "        Long forecast = 8 timestep\n",
    "        Short forecast = 4 timestep\n",
    "        By deduct different forecast at same valid time, expect the BEC structure\n",
    "        can be revealed.\n",
    "        \"\"\"\n",
    "        # Algorithm parameter\n",
    "        long_forecast_length = 8\n",
    "        short_forecast_length = 4\n",
    "        forecast_length = long_forecast_length + 1\n",
    "        N_samples = np.shape(x_a_all)[0]\n",
    "        # Init\n",
    "        samples = np.zeros((N_samples, forecast_length, np.shape(x_a_all)[-2], 1))\n",
    "        # Forecast in each sampled analysis time\n",
    "        for idx_samples in range(N_samples):\n",
    "            current_x_b = x_a_all[idx_samples]\n",
    "            samples[idx_samples,0] = current_x_b\n",
    "            for idx_forecast in range(forecast_length-1):\n",
    "                # Forecast\n",
    "                new_x_b = self.__model(current_x_b)\n",
    "                current_x_b = new_x_b\n",
    "                samples[idx_samples,idx_forecast+1] = current_x_b\n",
    "        # Deduct different forecast length at same valid time \n",
    "        samples_diff = samples[:-(long_forecast_length-short_forecast_length),long_forecast_length] - samples[(long_forecast_length-short_forecast_length):,short_forecast_length]\n",
    "        # Calculate statistical BEC\n",
    "        NMC_B = np.zeros((np.shape(x_a_all)[-2], np.shape(x_a_all)[-2]))\n",
    "        for i in range(len(samples_diff)):\n",
    "            d = samples_diff[i]\n",
    "            NMC_B += (d@d.T/(np.shape(samples_diff)[0]-1))\n",
    "        # Inflate\n",
    "        NMC_B *= inflation\n",
    "        return NMC_B\n",
    "    def set_B(self, B):\n",
    "        self.__B = B\n",
    "        self.__Bi = np.linalg.inv(self.__B)\n",
    "        return None\n",
    "    def get_B(self):\n",
    "        return self.__B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed898c2e-6555-4f73-a9b5-d4e396988fca",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 4DVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4cc5f11-b201-452b-841f-b44550ad4a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simulator_4DVar():\n",
    "    \"\"\"\n",
    "    Implement forecast-analysis cycle using 4DVar scheme\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 nature_run,\n",
    "                 observation,\n",
    "                 assimilation_window):\n",
    "        self.__observation = observation\n",
    "        self.__initial_x_a = nature_run.get_Initial_data()\n",
    "        self.__initial_x_b = np.full(self.__initial_x_a.shape, np.nan, dtype = \"f8\")\n",
    "        self.__B = np.eye(nature_run.get_Dimension())*observation.get_Rstd()**2\n",
    "        self.__Bi = np.linalg.inv(self.__B)\n",
    "        self.__func = nature_run.get_Governing_equation()\n",
    "        self.__assimilation_window = assimilation_window\n",
    "        self.__dT = nature_run.get_unit_timestep()\n",
    "        self.__nT = nature_run.get_total_timestep()\n",
    "        return None\n",
    "    def __model(self, x):\n",
    "        \"\"\"\n",
    "        Doing time integration using Runge-Kutta 5 scheme\n",
    "        \"\"\"\n",
    "        k1 = self.__func(x)\n",
    "        k2 = self.__func(x + k1*self.__dT/2)\n",
    "        k3 = self.__func(x + (3*k1+k2)*self.__dT/16)\n",
    "        k4 = self.__func(x + k3*self.__dT/2)\n",
    "        k5 = self.__func(x + (-3*k2+6*k3+9*k4)*self.__dT/16)\n",
    "        k6 = self.__func(x + (k1+4*k2+6*k3-12*k4+8*k5)*self.__dT/7)\n",
    "        new_x = x + (self.__dT/90)*(7*k1 + 32*k3 + 12*k4 + 32*k5 + 7*k6)\n",
    "        return new_x\n",
    "    def __increment_4DVar(self, x_b, y_o, H, R):\n",
    "        \"\"\"\n",
    "        Data assimilation using 4DVar, in this case, using incremental form\n",
    "        \"\"\"\n",
    "        def f(dx, x_a, x_b, d, Hl, M, Ri):\n",
    "            \"\"\"\n",
    "            Cost function of 4DVar in incremental form\n",
    "            J = 1/2*(dx.T@B-1@dx + np.sum((H@M@dx - d)@R-1(H@M@dx - d)))\n",
    "            \"\"\"\n",
    "            # Rename\n",
    "            increment = dx\n",
    "            past_state = x_a\n",
    "            current_state = past_state + increment\n",
    "            background_state = x_b\n",
    "            innovation = d\n",
    "            LinObsOp = Hl\n",
    "            LinModelOp = M\n",
    "            \n",
    "            J_b = (1/2)*(current_state - background_state).T@self.__Bi@(current_state - background_state)\n",
    "            J_o = 0\n",
    "            for i in range(len(d)):\n",
    "                J_o += (1/2)*(LinObsOp[i]@LinModelOp[i]@increment-innovation[i]).T@Ri[i]@(LinObsOp[i]@LinModelOp[i]@increment-innovation[i])\n",
    "            J = J_b + J_o\n",
    "            return J\n",
    "        def fprime(dx, x_a, x_b, d, Hl, M, Ri):\n",
    "            \"\"\"\n",
    "            Jacobian of cost function of 4DVar in incremental form\n",
    "            dJ = B-1@dx + np.sum(M@H.T@R-1@(H@M@dx - d))\n",
    "            \"\"\"\n",
    "            # Rename\n",
    "            increment = dx\n",
    "            past_state = x_a\n",
    "            current_state = past_state + increment\n",
    "            background_state = x_b\n",
    "            innovation = d\n",
    "            LinObsOp = Hl\n",
    "            LinModelOp = M\n",
    "            \n",
    "            J_b = self.__Bi@(current_state - background_state)\n",
    "            J_o = 0\n",
    "            for i in range(len(y_o)):\n",
    "                J_o += LinModelOp[i].T@LinObsOp[i].T@Ri[i]@(LinObsOp[i]@LinModelOp[i]@increment-innovation[i])\n",
    "            \n",
    "            J = J_b + J_o\n",
    "            return J\n",
    "        def line_search(f, grad, dx, args = ()):\n",
    "            \"\"\"\n",
    "            Modified from Golden Section Line Search\n",
    "            Given object function, its gradient and reference state\n",
    "            Find step (p_k) that minimize f, which is\n",
    "            f(dx + p_k * grad) < f(dx)\n",
    "            ***Still unstable due to CFL condition\n",
    "            \"\"\"\n",
    "            # Algorithm parameter\n",
    "            upper_bound = 1\n",
    "            lower_bound = -1\n",
    "            alpha = (3 - np.sqrt(5)) / 2\n",
    "            # Initialize\n",
    "            a0 = lower_bound\n",
    "            b0 = upper_bound\n",
    "            a1 = a0 + alpha*(b0-a0)\n",
    "            b1 = b0 - alpha*(b0-a0)\n",
    "            reference = f(dx, *args)\n",
    "            \n",
    "            # Find best step\n",
    "            while True:\n",
    "                result_a1 = f(dx+a1*grad, *args)\n",
    "                result_b1 = f(dx+b1*grad, *args)\n",
    "                if (result_a1 < reference):\n",
    "                    best_p = a1\n",
    "                    break\n",
    "                if (result_b1 < reference):\n",
    "                    best_p = b1\n",
    "                    break\n",
    "                if (result_a1 < result_b1):\n",
    "                    b0 = b1\n",
    "                    b1 = a1\n",
    "                    a1 = a0 + alpha*(b0-a0)\n",
    "                else:\n",
    "                    a0 = a1\n",
    "                    a1 = b1\n",
    "                    b1 = b0 - alpha*(b0-a0)\n",
    "            return best_p\n",
    "        def PR_beta(g0, g1):\n",
    "            \"\"\"\n",
    "            Polak-Ribiere method for conjugate gradient method \n",
    "            \"\"\"\n",
    "            return (g1.T@(g1-g0))/(g0.T@g0)\n",
    "        def minimize(x_b, y_o, H, R):\n",
    "            \"\"\"\n",
    "            Minimize cost function using CG method\n",
    "            \"\"\"\n",
    "            # Algorithm parameter\n",
    "            maxiter_inner = int(1e6)\n",
    "            maxiter_outer = int(1e6)\n",
    "            # First guess, x = x_b\n",
    "            x_a = np.copy(x_b)\n",
    "            for out_loop in range(maxiter_outer):\n",
    "                # Initial minimization parameter\n",
    "                jac_old = np.full(np.shape(x_b), 0, dtype = \"f8\")\n",
    "                jac_new = np.full(np.shape(x_b), 0, dtype = \"f8\")\n",
    "                beta = None\n",
    "                grad = 0\n",
    "                \n",
    "                # Initial increment\n",
    "                dx = np.full(np.shape(x_b), 0, dtype = \"f8\")\n",
    "                # Initial model jacobian\n",
    "                M = []\n",
    "                M.append(np.eye(x_b.shape[0])) # The initial element is actually not jacobian\n",
    "                # Initial model trajectory\n",
    "                base_trajectory = []\n",
    "                base_trajectory.append(x_a)\n",
    "                # Initial observation operator jacobian\n",
    "                Hl = []\n",
    "                Hl.append(jacobian(H[0], base_trajectory[0]))\n",
    "                # Initial innovation\n",
    "                d = []\n",
    "                d.append(y_o[0]-H[0](base_trajectory[0]))\n",
    "                \n",
    "                # Complete TLM (Tangent Linear Model)\n",
    "                for i in range(len(y_o)-1):\n",
    "                    M.append(jacobian(self.__model, base_trajectory[i]))\n",
    "                    base_trajectory.append(self.__model(base_trajectory[i]))\n",
    "                    d.append(y_o[i+1]-H[i+1](base_trajectory[i+1]))\n",
    "                    Hl.append(jacobian(H[i+1], base_trajectory[i+1]))\n",
    "                M = np.array(M, dtype = \"f8\")\n",
    "                base_trajectory = np.array(base_trajectory, dtype = \"f8\")\n",
    "                \n",
    "                # Combine model operator\n",
    "                for i in range(len(M)-1):\n",
    "                    M[i+1] = M[i+1]@M[i]\n",
    "                # \n",
    "                Ri = []\n",
    "                for i in range(len(R)):\n",
    "                    Ri.append(np.linalg.inv(R[i]))\n",
    "                \n",
    "                # Control parameter\n",
    "                args = (x_a, x_b, d, Hl, M, Ri)\n",
    "                for in_loop in range(maxiter_inner):\n",
    "                    # Find gradient\n",
    "                    jac = fprime(dx, *args)\n",
    "                    jac_new = jac\n",
    "                    beta = PR_beta(jac_old, jac_new) if in_loop != 0 else 1\n",
    "                    grad = -(jac_new) + beta*grad     \n",
    "                    jac_old = jac_new\n",
    "                    p_k = line_search(f, grad, dx, args = args)\n",
    "                    delta = p_k*grad\n",
    "                    # Update dx\n",
    "                    dx += delta\n",
    "                    if (np.linalg.norm(delta) < 1e-4):\n",
    "                        break\n",
    "                # Update x\n",
    "                x_a += dx\n",
    "                if (np.linalg.norm(dx) < 1e-3):\n",
    "                    break\n",
    "            return x_a\n",
    "        return minimize(x_b, y_o, H, R)  \n",
    "        \n",
    "    def Cycle(self):\n",
    "        \"\"\"\n",
    "        Forecast-Analysis Cycle\n",
    "        \"\"\"\n",
    "        observation = self.__observation\n",
    "        x_b_all = self.__initial_x_b[np.newaxis]\n",
    "        x_a_all = self.__initial_x_a[np.newaxis]\n",
    "        ct = 0\n",
    "        used_observation_time = 0\n",
    "        while ct < (self.__nT-1):\n",
    "            \n",
    "            # print(ct*self.__dT)\n",
    "            # Forecast\n",
    "            x_b = self.__model(x_a_all[ct])[np.newaxis]\n",
    "            x_b_all = np.vstack([x_b_all, x_b])\n",
    "            # Analysis\n",
    "            x_b = x_b_all[ct+1]\n",
    "            if (used_observation_time>=(ct+1)*self.__dT):\n",
    "                x_a = x_b[np.newaxis]\n",
    "            else:\n",
    "                args = ((ct+1)*self.__dT, (ct+self.__assimilation_window)*self.__dT)\n",
    "                y_o = observation.get_Data(args)\n",
    "                H = observation.get_Operator(args)\n",
    "                R = observation.get_Covariance(args)\n",
    "                if y_o is not None:\n",
    "                    x_a = self.__increment_4DVar(x_b, y_o, H, R)[np.newaxis]\n",
    "                    used_observation_time = (ct+self.__assimilation_window)*self.__dT\n",
    "                else:\n",
    "                    x_a = x_b[np.newaxis]\n",
    "            x_a_all = np.vstack([x_a_all, x_a])\n",
    "            # next\n",
    "            ct += 1\n",
    "        return x_a_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe438d4f-8ec5-41c0-88a2-bfdaa1d54d55",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## EKF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45af4da2-60a3-4a68-9c53-6fb2cbaddc58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Simulator_EKF():\n",
    "    \"\"\"\n",
    "    Implement forecast-analysis cycle using EKF scheme\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 nature_run,\n",
    "                 observation):\n",
    "        self.__observation = observation\n",
    "        self.__initial_x_a = nature_run.get_Initial_data()\n",
    "        self.__initial_x_b = np.full(self.__initial_x_a.shape, np.nan, dtype = \"f8\")\n",
    "        self.__B = np.eye(nature_run.get_Dimension())*observation.get_Rstd()**2\n",
    "        self.__func = nature_run.get_Governing_equation()\n",
    "        self.__dT = nature_run.get_unit_timestep()\n",
    "        self.__nT = nature_run.get_total_timestep()\n",
    "        return None\n",
    "    def __model(self, x):\n",
    "        \"\"\"\n",
    "        Doing time integration using Runge-Kutta 5 scheme\n",
    "        \"\"\"\n",
    "        k1 = self.__func(x)\n",
    "        k2 = self.__func(x + k1*self.__dT/2)\n",
    "        k3 = self.__func(x + (3*k1+k2)*self.__dT/16)\n",
    "        k4 = self.__func(x + k3*self.__dT/2)\n",
    "        k5 = self.__func(x + (-3*k2+6*k3+9*k4)*self.__dT/16)\n",
    "        k6 = self.__func(x + (k1+4*k2+6*k3-12*k4+8*k5)*self.__dT/7)\n",
    "        new_x = x + (self.__dT/90)*(7*k1 + 32*k3 + 12*k4 + 32*k5 + 7*k6)\n",
    "        return new_x\n",
    "    def __EKF_forecast(self, x_a, Ba):\n",
    "        \"\"\"\n",
    "        Data assimilation using Extended Kalman Filter\n",
    "        Forecast step\n",
    "        \"\"\"\n",
    "        Q = 0\n",
    "        M = jacobian(self.__model, x_a)\n",
    "        Bf = M@Ba@M.T + Q\n",
    "        return Bf\n",
    "    def __EKF_analysis(self, x_b, y_o, H, Bf, R):\n",
    "        \"\"\"\n",
    "        Data assimilation using Extended Kalman Filter\n",
    "        Analysis step\n",
    "        \"\"\"\n",
    "        d = y_o - H(x_b)\n",
    "        Hl = jacobian(H, x_b)\n",
    "        K = Bf@Hl.T@np.linalg.inv(Hl@Bf@Hl.T + R)\n",
    "        x_a = x_b + K@d\n",
    "        I = np.eye(len(x_b))\n",
    "        Ba = (I - K@Hl)@Bf\n",
    "        \n",
    "        return x_a, Ba\n",
    "    def __EKF_MUL_inflation(self, B, alpha = 1):\n",
    "        return alpha*B\n",
    "    def __EKF_ADD_inflation(self, Ba, alpha = 0):\n",
    "        return Ba + np.eye(len(Ba))*alpha\n",
    "    def __EKF_RTP_inflation(self, Ba, Bf, alpha = 0):\n",
    "        return (1-alpha)*Ba + alpha*Bf\n",
    "    def Cycle(self, MUL_param = 1, ADD_param = 0, RTP_param = 0):\n",
    "        \"\"\"\n",
    "        Forecast-Analysis Cycle\n",
    "        \"\"\"\n",
    "        observation = self.__observation\n",
    "        x_b_all = self.__initial_x_b[np.newaxis]\n",
    "        x_a_all = self.__initial_x_a[np.newaxis]\n",
    "        Bf = self.__B\n",
    "        Ba = self.__B\n",
    "\n",
    "        ct = 0\n",
    "        while ct < (self.__nT-1):\n",
    "            \n",
    "            # Forecast\n",
    "            x_b = self.__model(x_a_all[ct])[np.newaxis]\n",
    "            Bf = self.__EKF_forecast(x_a_all[ct], Ba)\n",
    "            Bf = self.__EKF_MUL_inflation(Bf, alpha = MUL_param)\n",
    "            \n",
    "            x_b_all = np.vstack([x_b_all, x_b]) \n",
    "            # Analysis\n",
    "            x_b = x_b_all[ct+1]\n",
    "            y_o = observation.get_Data((ct+1)*self.__dT)\n",
    "            H = observation.get_Operator((ct+1)*self.__dT)\n",
    "            R = observation.get_Covariance((ct+1)*self.__dT)\n",
    "            if y_o is not None:\n",
    "                x_a, Ba = self.__EKF_analysis(x_b, y_o, H, Bf, R)\n",
    "                x_a = x_a[np.newaxis]\n",
    "                Ba = self.__EKF_RTP_inflation(Ba, Bf, alpha = RTP_param)\n",
    "                Ba = self.__EKF_ADD_inflation(Ba, alpha = ADD_param)\n",
    "            else:\n",
    "                x_a = x_b[np.newaxis]\n",
    "                Ba = Bf\n",
    "            \n",
    "            x_a_all = np.vstack([x_a_all, x_a])\n",
    "            #\n",
    "            ct += 1\n",
    "        return x_a_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263f5a2b-49ed-4dc4-8002-e06522cd245e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## PO-EnKF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "46b61f27-8caa-49e6-8716-07da7b899d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simulator_EnKF():\n",
    "    \"\"\"\n",
    "    Implement forecast-analysis cycle using EnKF scheme\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 nature_run,\n",
    "                 observation):\n",
    "        self.__observation = observation\n",
    "        self.__initial_x_a = nature_run.get_Ensemble_initial_data()\n",
    "        self.__initial_x_b = np.full(self.__initial_x_a.shape, np.nan, dtype = \"f8\")\n",
    "        self.__B = np.eye(nature_run.get_Dimension())*observation.get_Rstd()**2\n",
    "        self.__Bi = np.linalg.inv(self.__B)\n",
    "        self.__func = nature_run.get_Governing_equation()\n",
    "        self.__dT = nature_run.get_unit_timestep()\n",
    "        self.__nT = nature_run.get_total_timestep()\n",
    "        return None\n",
    "\n",
    "    def __model(self, x):\n",
    "        \"\"\"\n",
    "        Doing time integration using Runge-Kutta 5 scheme\n",
    "        \"\"\"\n",
    "        k1 = self.__func(x)\n",
    "        k2 = self.__func(x + k1*self.__dT/2)\n",
    "        k3 = self.__func(x + (3*k1+k2)*self.__dT/16)\n",
    "        k4 = self.__func(x + k3*self.__dT/2)\n",
    "        k5 = self.__func(x + (-3*k2+6*k3+9*k4)*self.__dT/16)\n",
    "        k6 = self.__func(x + (k1+4*k2+6*k3-12*k4+8*k5)*self.__dT/7)\n",
    "        new_x = x + (self.__dT/90)*(7*k1 + 32*k3 + 12*k4 + 32*k5 + 7*k6)\n",
    "        return new_x\n",
    "    def __ensemble_mean(self, x):\n",
    "        \"\"\"\n",
    "        Derive ensemble mean\n",
    "        \"\"\"\n",
    "        return np.mean(x, axis = 0)\n",
    "    def __ensemble_BEC(self, x, x_mean):\n",
    "        \"\"\"\n",
    "        Derive ensemble forecast\n",
    "        \"\"\"\n",
    "        B = np.zeros((x_mean.shape[0], x_mean.shape[0]), dtype = \"f8\")\n",
    "        for i in range(len(x)):\n",
    "            \n",
    "            B += (x[i]-x_mean)@(x[i]-x_mean).T\n",
    "        B /= (len(x)-1)\n",
    "        return B\n",
    "    def __EnKF_forecast(self, x_a, Ba):\n",
    "        \"\"\"\n",
    "        Data assimilation using Extended Kalman Filter\n",
    "        Forecast step\n",
    "        \"\"\"\n",
    "        Q = 0\n",
    "        M = jacobian(self.__model, x_a)\n",
    "        Bf = M@Ba@M.T + Q\n",
    "        return Bf\n",
    "    def __EnKF_analysis(self, x_b, x_b_mean, y_o, H, R, Bf):\n",
    "        \"\"\"\n",
    "        Derive ensemble Kalman gain, and update ensemble state\n",
    "        PH.T = (x_b - H(x_b_mean))@(x_b - H(x_b_mean)).T\n",
    "        HPH.T = (H(x_b) - H(x_b_mean))@(H(x_b) - H(x_b_mean)).T\n",
    "        K = (PH.T)/(HPH.T + R)\n",
    "        \"\"\"\n",
    "        Hl = jacobian(H, x_b_mean)\n",
    "        K = Bf@Hl.T@np.linalg.inv(Hl@Bf@Hl.T+R)\n",
    "#         Hx = []\n",
    "#         for i in range(len(x_b)):\n",
    "#             Hx.append(H(x_b[i]))\n",
    "#         Hx = np.array(Hx, dtype = \"f8\")\n",
    "#         Hx_mean = self.__ensemble_mean(Hx)\n",
    "        \n",
    "#         P_HlT = np.zeros((Bf.shape[0], R.shape[0]), dtype = \"f8\")\n",
    "#         for i in range(len(x_b)):\n",
    "#             P_HlT += (x_b[i]-x_b_mean)@(Hx[i]-Hx_mean).T\n",
    "#         P_HlT /= (len(x_b)-1)\n",
    "#         Hl_P_HlT = np.zeros((R.shape[0], R.shape[0]), dtype = \"f8\")\n",
    "#         for i in range(len(x_b)):\n",
    "#             Hl_P_HlT += (Hx[i]-Hx_mean)@(Hx[i]-Hx_mean).T\n",
    "#         Hl_P_HlT /= (len(x_b)-1)\n",
    "#         K = P_HlT@np.linalg.inv(Hl_P_HlT+R)\n",
    "        \n",
    "        x_a = []\n",
    "        for i in range(len(x_b)):\n",
    "            x_a.append(x_b[i]+K@(y_o[i]-H(x_b[i])))\n",
    "        x_a = np.array(x_a, dtype = \"f8\")\n",
    "        \n",
    "        I = np.eye(len(x_b_mean))\n",
    "        Ba = (I - K@Hl)@Bf\n",
    "        \n",
    "        return x_a, Ba\n",
    "    def __EnKF_B_localization(self, Bf, L = 5):\n",
    "        for i in range(Bf.shape[0]):\n",
    "            for j in range(Bf.shape[1]):\n",
    "                distance = np.abs(i-j)%20\n",
    "                Bf[i,j] = Bf[i,j]*np.exp(-(distance**2)/(2*L**2))\n",
    "        return Bf\n",
    "    def __EnKF_MUL_inflation(self, B, alpha = 1):\n",
    "        return alpha*B\n",
    "    def __EnKF_ADD_inflation(self, Bf, alpha = 0):\n",
    "        return Bf + np.eye(len(Bf))*alpha\n",
    "    def __EnKF_RTP_inflation(self, Ba, Bf, alpha = 0):\n",
    "        return (1-alpha)*Ba + alpha*Bf\n",
    "    def Cycle(self, Radius = 40, MUL_param = 1, ADD_param = 0, RTP_param = 0):\n",
    "        \"\"\"\n",
    "        Forecast-Analysis Cycle\n",
    "        \"\"\"\n",
    "        observation = self.__observation\n",
    "        x_b_all = self.__initial_x_b[np.newaxis]\n",
    "        x_b_mean_all = self.__ensemble_mean(self.__initial_x_b)[np.newaxis]\n",
    "        x_a_all = self.__initial_x_a[np.newaxis]\n",
    "        x_a_mean_all = self.__ensemble_mean(self.__initial_x_a)[np.newaxis]\n",
    "        Bf = self.__ensemble_BEC(x_b_all[-1], x_b_mean_all[-1])\n",
    "        Ba = self.__ensemble_BEC(x_a_all[-1], x_a_mean_all[-1])\n",
    "        \n",
    "        ct = 0\n",
    "        while ct < (self.__nT-1):\n",
    "            # print(ct*self.__dT)\n",
    "            # Forecast\n",
    "            x_b = self.__model(x_a_all[ct])[np.newaxis]\n",
    "            x_b_mean = self.__ensemble_mean(x_b[0])[np.newaxis]\n",
    "            Bf = self.__ensemble_BEC(x_b[0], x_b_mean[0])\n",
    "            Bf = self.__EnKF_ADD_inflation(Bf, alpha = ADD_param)\n",
    "            Bf = self.__EnKF_B_localization(Bf, Radius)\n",
    "            Bf = self.__EnKF_MUL_inflation(Bf, alpha = MUL_param)\n",
    "            \n",
    "            x_b_all = np.vstack([x_b_all, x_b])\n",
    "            x_b_mean_all = np.vstack([x_b_mean_all, x_b_mean])\n",
    "            \n",
    "            # Analysis\n",
    "            x_b = x_b_all[ct+1]\n",
    "            x_b_mean = x_b_mean_all[ct+1]\n",
    "            y_o = observation.get_Data((ct+1)*self.__dT)\n",
    "            H = observation.get_Operator((ct+1)*self.__dT)\n",
    "            R = observation.get_Covariance((ct+1)*self.__dT)\n",
    "            if y_o is not None:\n",
    "                np.random.seed(int(ct*self.__nT*9527))\n",
    "                virtual_y_o = np.random.multivariate_normal(y_o.flatten(), R*(x_b_all.shape[1]-1)/x_b_all.shape[1], size = x_b_all.shape[1])[:,:,np.newaxis]\n",
    "                x_a, Ba = self.__EnKF_analysis(x_b, x_b_mean, virtual_y_o, H, R, Bf)\n",
    "                x_a = x_a[np.newaxis]\n",
    "                x_a_mean = self.__ensemble_mean(x_a[0])[np.newaxis]\n",
    "            else:\n",
    "                x_a = x_b[np.newaxis]\n",
    "                x_a_mean = x_b_mean[np.newaxis]\n",
    "                Ba = Bf\n",
    "            x_a_all = np.vstack([x_a_all, x_a])\n",
    "            x_a_mean_all = np.vstack([x_a_mean_all, x_a_mean])\n",
    "            #\n",
    "            ct += 1\n",
    "        return (x_b_all, x_b_mean_all), (x_a_all, x_a_mean_all)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pcore_env",
   "language": "python",
   "name": "pcore_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
